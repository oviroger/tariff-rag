# Resultados de EvaluaciÃ³n - Sistema RAG de ClasificaciÃ³n Arancelaria

**Fecha:** 6 de noviembre de 2025  
**Dataset:** ASGARD (100 queries con ground truth real)  
**Modelo:** Gemini con bÃºsqueda hÃ­brida OpenSearch

---

## ğŸ“Š MÃ©tricas del Clasificador

| MÃ©trica | Valor | DescripciÃ³n |
|---------|-------|-------------|
| **Accuracy@1** | **25.0%** | Porcentaje de consultas donde la predicciÃ³n top-1 es correcta |
| **Accuracy@3** | **26.0%** | Porcentaje de consultas donde el cÃ³digo correcto estÃ¡ en el top-3 |
| **MRR@3** | **0.255** | Mean Reciprocal Rank - posiciÃ³n promedio del cÃ³digo correcto |
| **Macro-F1** | **0.175** | F1 promedio entre todas las clases (capÃ­tulos HS) |
| **Micro-F1** | **0.250** | F1 global considerando todos los casos |
| **ECE@10** | **N/A** | Expected Calibration Error (requiere scores de probabilidad) |

---

## ğŸ” MÃ©tricas de Retrieval (100 queries Ã— 5 docs)

AnotaciÃ³n completada: 500/500 documentos (92 relevantes, 408 no relevantes)

| MÃ©trica | @1 | @3 | @5 |
|--------:|:--:|:--:|:--:|
| Recall  | 0.24 | 0.41 | 0.48 |
| Precision | 0.24 | 0.207 | 0.184 |
| nDCG    | 0.24 | 0.338 | 0.366 |

Otras:
- MAP: 0.321
- NÃºmero de queries: 100

Archivo: `evaluation/results/retrieval_asgard_metrics.json`

---

## ğŸ¯ InterpretaciÃ³n de Resultados

### PrecisiÃ³n del Clasificador
- **1 de cada 4 consultas** recibe el cÃ³digo HS correcto como primera predicciÃ³n
- El sistema muestra **baja mejora** entre top-1 y top-3 (solo +1%), indicando que cuando falla, raramente el cÃ³digo correcto estÃ¡ en posiciones 2-3
- El **MRR de 0.255** confirma que la mayorÃ­a de aciertos estÃ¡n en la primera posiciÃ³n

### F1 Scores
- **Micro-F1 = 0.25** coincide con Accuracy@1 (esperado en clasificaciÃ³n multiclase)
- **Macro-F1 = 0.175** indica desbalance en el desempeÃ±o entre diferentes capÃ­tulos HS
- La diferencia (0.25 vs 0.175) sugiere que el sistema funciona mejor en algunos capÃ­tulos que en otros

---

## ğŸ” AnÃ¡lisis del Dataset

- **Total de consultas:** 100
- **CapÃ­tulos HS cubiertos:** 85 (del 04 al 98)
- **DistribuciÃ³n:** ~1 consulta por capÃ­tulo
- **Fuente:** Archivo ASGARD.csv con declaraciones reales de importaciÃ³n/exportaciÃ³n
- **Ventaja:** Ground truth verificado (cÃ³digos HS oficiales de aduana)

---

## âš ï¸ Observaciones

### Advertencias de scikit-learn
Durante el cÃ¡lculo se generaron warnings indicando que el nÃºmero de clases Ãºnicas (cÃ³digos HS diferentes) es mayor al 50% de las muestras. Esto es **normal** para este tipo de evaluaciÃ³n donde:
- Hay 100 queries
- Hay ~85 cÃ³digos HS Ãºnicos (uno por capÃ­tulo)
- Es un problema de clasificaciÃ³n multiclase con muchas clases y pocas muestras por clase

### Limitaciones
1. **Dataset pequeÃ±o:** 100 queries es adecuado para una tesis de maestrÃ­a pero insuficiente para conclusiones estadÃ­sticamente robustas
2. **Cobertura dispersa:** 1 query por capÃ­tulo no permite evaluar consistencia intra-capÃ­tulo
3. **Falta ECE:** No se calculÃ³ calibraciÃ³n porque el endpoint `/classify` no devuelve probabilidades, solo rankings

---

## ğŸ“ PrÃ³ximos Pasos

### Para mejorar la evaluaciÃ³n:
1. âœ… **Clasificador evaluado** con ground truth automÃ¡tico
2. âœ… **Retrieval evaluado** con anotaciÃ³n completa y mÃ©tricas guardadas
3. â³ **Operacional:** Generar logs con warmup y exportar mÃ©tricas de latencia/throughput

### Para mejorar el modelo:
- Analizar fallos por capÃ­tulo para identificar patrones
- Incrementar dataset de entrenamiento con mÃ¡s queries ASGARD
- Implementar reranking o fine-tuning especÃ­fico para cÃ³digos HS problemÃ¡ticos
- Agregar explicabilidad para entender predicciones incorrectas

---

## ğŸ“‚ Archivos Generados

```
evaluation/
â”œâ”€â”€ queries_asgard.txt                          # 100 queries (texto plano)
â”œâ”€â”€ queries_asgard_metadata.json                # Metadata completo
â”œâ”€â”€ queries_asgard_groundtruth.csv              # Ground truth con cÃ³digos HS
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ eval_clasificador_hs6_asgard.csv        # Predicciones + ground truth
â”‚   â”œâ”€â”€ eval_clasificador_hs6_asgard_metrics.csv # Formato normalizado
â”‚   â””â”€â”€ eval_retrieval_asgard.csv               # 500 docs para anotar
â”œâ”€â”€ results/
â”‚   â””â”€â”€ classifier_asgard_metrics.json          # MÃ©tricas finales
â””â”€â”€ tools/
    â”œâ”€â”€ generate_from_asgard.py                 # Extractor de queries
    â”œâ”€â”€ merge_groundtruth.py                    # FusiÃ³n con ground truth
    â””â”€â”€ reshape_eval_for_metrics.py             # NormalizaciÃ³n de formato
```

---

**Nota:** Los warnings de scikit-learn son informativos y no afectan la validez de las mÃ©tricas. Reflejan la naturaleza del problema: clasificaciÃ³n multiclase con alta cardinalidad y pocas muestras por clase.
