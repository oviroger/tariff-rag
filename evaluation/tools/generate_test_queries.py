#!/usr/bin/env python3
"""
Script para generar queries de evaluaci√≥n autom√°ticamente desde el corpus.
Extrae descripciones de productos y c√≥digos HS de OpenSearch y MySQL.
"""
import argparse
import csv
import json
import random
import re
from typing import List, Dict, Tuple
import sys
from pathlib import Path

# Agregar el directorio ra√≠z al path para importar m√≥dulos de la app
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from opensearchpy import OpenSearch
    from opensearchpy.exceptions import ConnectionError as OSConnectionError
except ImportError:
    print("‚ùå Error: opensearch-py no est√° instalado")
    print("Instale con: pip install opensearch-py")
    sys.exit(1)

try:
    import mysql.connector
    HAS_MYSQL = True
except ImportError:
    print("‚ö†Ô∏è Warning: mysql-connector-python no instalado. No se extraer√°n queries de MySQL.")
    HAS_MYSQL = False


def connect_opensearch(host: str) -> OpenSearch:
    """Conectar a OpenSearch."""
    try:
        client = OpenSearch(
            hosts=[host],
            use_ssl=False,
            verify_certs=False,
            ssl_show_warn=False,
            timeout=30
        )
        # Test connection
        client.info()
        return client
    except Exception as e:
        print(f"‚ùå Error conectando a OpenSearch: {e}")
        sys.exit(1)


def extract_hs_codes_from_text(text: str) -> List[str]:
    """Extraer c√≥digos HS del texto (formato: XXXX.XX o similares)."""
    # Patr√≥n para c√≥digos HS de 4-6 d√≠gitos con punto opcional
    pattern = r'\b\d{2,4}(?:\.\d{2})?\b'
    codes = re.findall(pattern, text)
    return list(set(codes))  # √önicos


def extract_product_descriptions(text: str, max_words: int = 15) -> List[str]:
    """Extraer descripciones de productos del texto."""
    descriptions = []
    
    # Patrones comunes en nomenclatura HS
    product_keywords = [
        'animales', 'carne', 'pescado', 'l√°cteos', 'frutas', 'legumbres', 'caf√©', 't√©',
        'cereales', 'productos', 'grasas', 'aceites', 'preparaciones', 'bebidas',
        'tabaco', 'materias', 'pl√°stico', 'caucho', 'pieles', 'cuero', 'madera',
        'papel', 'cart√≥n', 'textiles', 'calzado', 'piedra', 'cemento', 'vidrio',
        'perlas', 'metales', 'hierro', 'acero', 'cobre', 'aluminio', 'plomo',
        'herramientas', 'm√°quinas', 'aparatos', 'veh√≠culos', 'aeronaves', 'barcos',
        'instrumentos', 'armas', 'muebles', 'juguetes', 'manufacturas'
    ]
    
    # Buscar l√≠neas que parecen descripciones de productos
    lines = text.split('\n')
    for line in lines:
        line = line.strip()
        line_lower = line.lower()
        
        # Filtrar l√≠neas que parecen descripciones
        if len(line) > 15 and len(line) < 250:
            words = line.split()
            if 2 <= len(words) <= max_words:
                # Verificar que contenga palabras clave de productos
                has_keyword = any(keyword in line_lower for keyword in product_keywords)
                
                # Verificar que contenga m√°s letras que n√∫meros
                letters = sum(c.isalpha() for c in line)
                digits = sum(c.isdigit() for c in line)
                
                if (has_keyword or letters > digits * 2) and letters > 20:
                    # Limpiar caracteres especiales al inicio/final
                    line_clean = re.sub(r'^[^\w\s]+|[^\w\s]+$', '', line)
                    if len(line_clean) > 15:
                        descriptions.append(line_clean)
    
    return descriptions


def sample_opensearch_queries(
    os_client: OpenSearch,
    index: str,
    num_samples: int = 100,
    max_per_category: int = 10
) -> List[Dict]:
    """
    Extraer queries de muestra desde OpenSearch.
    Intenta obtener diversidad de categor√≠as HS.
    """
    queries = []
    
    print(f"üì• Extrayendo {num_samples} documentos de OpenSearch...")
    
    try:
        # Obtener documentos aleatorios
        response = os_client.search(
            index=index,
            body={
                "size": num_samples,
                "query": {
                    "function_score": {
                        "query": {"match_all": {}},
                        "random_score": {}
                    }
                },
                "_source": ["text", "hs_code", "title", "doc_id"]
            }
        )
        
        hits = response.get("hits", {}).get("hits", [])
        print(f"‚úì Obtenidos {len(hits)} documentos")
        
        # Agrupar por prefijo de c√≥digo HS (primeros 2 d√≠gitos)
        by_category = {}
        
        for hit in hits:
            source = hit.get("_source", {})
            text = source.get("text", "")
            hs_code = source.get("hs_code", "")
            title = source.get("title", "")
            
            if not text or len(text) < 50:
                continue
            
            # Extraer descripciones del texto
            descriptions = extract_product_descriptions(text)
            
            # Intentar extraer c√≥digos HS del texto
            hs_codes_in_text = extract_hs_codes_from_text(text)
            
            # Determinar categor√≠a (primeros 2 d√≠gitos del c√≥digo HS)
            category = hs_code[:2] if hs_code and len(hs_code) >= 2 else "00"
            
            if category not in by_category:
                by_category[category] = []
            
            # Agregar descripciones encontradas
            for desc in descriptions[:3]:  # M√°ximo 3 por documento
                if len(by_category[category]) < max_per_category:
                    query_data = {
                        "query": desc,
                        "hs_code": hs_code or (hs_codes_in_text[0] if hs_codes_in_text else ""),
                        "category": category,
                        "source": "opensearch"
                    }
                    by_category[category].append(query_data)
        
        # Recopilar todas las queries
        for category, category_queries in by_category.items():
            queries.extend(category_queries)
        
        print(f"‚úì Extra√≠das {len(queries)} queries de {len(by_category)} categor√≠as")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error extrayendo de OpenSearch: {e}")
    
    return queries


def sample_mysql_queries(
    host: str,
    port: int,
    database: str,
    user: str,
    password: str,
    num_samples: int = 50
) -> List[Dict]:
    """
    Extraer queries de muestra desde MySQL.
    Busca tablas con descripciones de productos y c√≥digos HS.
    """
    queries = []
    
    if not HAS_MYSQL:
        return queries
    
    print(f"üì• Extrayendo queries de MySQL...")
    
    try:
        conn = mysql.connector.connect(
            host=host,
            port=port,
            database=database,
            user=user,
            password=password
        )
        cursor = conn.cursor(dictionary=True)
        
        # Intentar encontrar tablas relevantes
        # Buscar tablas con columnas que contengan 'description', 'hs', 'product', etc.
        cursor.execute("SHOW TABLES")
        tables = [row[f'Tables_in_{database}'] for row in cursor.fetchall()]
        
        for table in tables:
            try:
                # Obtener columnas de la tabla
                cursor.execute(f"DESCRIBE {table}")
                columns = [row['Field'] for row in cursor.fetchall()]
                
                # Buscar columnas relevantes
                desc_col = next((c for c in columns if 'descripcion' in c.lower() or 'description' in c.lower() or 'producto' in c.lower() or 'product' in c.lower()), None)
                hs_col = next((c for c in columns if 'hs' in c.lower() or 'codigo' in c.lower() or 'code' in c.lower()), None)
                
                if desc_col:
                    # Construir query SQL
                    select_cols = [desc_col]
                    if hs_col:
                        select_cols.append(hs_col)
                    
                    query_sql = f"SELECT {', '.join(select_cols)} FROM {table} ORDER BY RAND() LIMIT {num_samples}"
                    cursor.execute(query_sql)
                    rows = cursor.fetchall()
                    
                    for row in rows:
                        desc = row.get(desc_col, "")
                        hs_code = row.get(hs_col, "") if hs_col else ""
                        
                        if desc and len(desc) > 10:
                            # Limpiar descripci√≥n
                            desc_clean = desc.strip()
                            if len(desc_clean) > 200:
                                desc_clean = desc_clean[:200] + "..."
                            
                            query_data = {
                                "query": desc_clean,
                                "hs_code": str(hs_code) if hs_code else "",
                                "category": str(hs_code)[:2] if hs_code else "00",
                                "source": f"mysql:{table}"
                            }
                            queries.append(query_data)
                    
                    print(f"  ‚úì {len(rows)} queries de tabla '{table}'")
            
            except Exception as e:
                # Tabla puede no ser accesible o tener problemas
                continue
        
        cursor.close()
        conn.close()
        
        print(f"‚úì Extra√≠das {len(queries)} queries de MySQL")
    
    except Exception as e:
        print(f"‚ö†Ô∏è Error conectando a MySQL: {e}")
    
    return queries


def generate_synthetic_queries(base_queries: List[Dict], num_synthetic: int = 20) -> List[Dict]:
    """
    Generar queries sint√©ticas basadas en las queries existentes.
    Crea variaciones a√±adiendo atributos comunes.
    """
    synthetic = []
    
    # Queries predefinidas comunes (casos t√≠picos de clasificaci√≥n arancelaria)
    predefined_queries = [
        # Electr√≥nica (Cap√≠tulo 85)
        "Smartphone con pantalla OLED",
        "Laptop HP 15 pulgadas",
        "Auriculares inal√°mbricos Bluetooth",
        "Tablet Android 10 pulgadas",
        "Cargador USB-C 65W",
        "Cable HDMI 2 metros",
        "Mouse inal√°mbrico",
        "Teclado mec√°nico RGB",
        "Monitor LED 27 pulgadas",
        "C√°mara web Full HD",
        
        # Alimentos (Cap√≠tulos 01-24)
        "Bananas frescas",
        "Manzanas rojas importadas",
        "Caf√© en grano tostado",
        "Arroz blanco largo",
        "Aceite de oliva virgen extra",
        "Chocolate con leche",
        "Queso parmesano",
        "Vino tinto reserva",
        "Cerveza artesanal",
        "T√© verde en bolsitas",
        
        # Textiles (Cap√≠tulos 50-63)
        "Camiseta de algod√≥n",
        "Pantalones vaqueros",
        "Zapatos deportivos",
        "Bolso de cuero genuino",
        "Chaqueta impermeable",
        "Toallas de ba√±o",
        "S√°banas de algod√≥n",
        
        # Veh√≠culos (Cap√≠tulo 87)
        "Neum√°ticos radiales 205/55R16",
        "Llantas de aleaci√≥n 17 pulgadas",
        "Bater√≠a de auto 12V",
        "Filtro de aceite automotriz",
        "Parabrisas delantero",
        
        # Maquinaria (Cap√≠tulo 84)
        "Bomba de agua centr√≠fuga",
        "Compresor de aire industrial",
        "Taladro el√©ctrico 500W",
        "Sierra circular",
        "Generador el√©ctrico 5KW",
        
        # Productos qu√≠micos (Cap√≠tulos 28-38)
        "Detergente l√≠quido",
        "Champ√∫ anticaspa",
        "Pintura acr√≠lica blanca",
        "Fertilizante NPK",
        "Insecticida en aerosol",
        
        # Juguetes y deportes (Cap√≠tulos 95-96)
        "Pelota de f√∫tbol oficial",
        "Bicicleta de monta√±a",
        "Mu√±eca de pl√°stico",
        "Raqueta de tenis",
        "Patineta el√©ctrica",
        
        # Muebles (Cap√≠tulo 94)
        "Silla de oficina ergon√≥mica",
        "Mesa de comedor de madera",
        "Colch√≥n queen size",
        "Estanter√≠a met√°lica",
        
        # Pl√°sticos (Cap√≠tulo 39)
        "Tubos PVC 2 pulgadas",
        "Contenedores pl√°sticos",
        "Bolsas pl√°sticas biodegradables",
        
        # Metales (Cap√≠tulos 72-83)
        "Alambre de acero galvanizado",
        "Tornillos de acero inoxidable",
        "L√°minas de aluminio",
        
        # Instrumentos (Cap√≠tulo 90)
        "Term√≥metro digital",
        "Gafas de sol polarizadas",
        "Tensi√≥metro digital",
        
        # Libros y papel (Cap√≠tulo 48-49)
        "Cuadernos universitarios",
        "Libro de texto",
        "Papel bond carta",
    ]
    
    # Atributos comunes para a√±adir variaci√≥n
    materials = ["de acero", "de pl√°stico", "de aluminio", "de madera", "de vidrio", "de algod√≥n", "de cuero"]
    sizes = ["grande", "peque√±o", "mediano", "extra grande"]
    colors = ["rojo", "azul", "negro", "blanco", "verde", "amarillo"]
    conditions = ["nuevo", "usado"]
    origins = ["importado de China", "importado de USA", "nacional"]
    brands = ["marca Samsung", "marca Apple", "marca Sony", "marca LG"]
    
    print(f"üî® Generando {num_synthetic} queries sint√©ticas...")
    
    # Primero agregar queries predefinidas
    num_predefined = min(len(predefined_queries), num_synthetic // 2)
    selected_predefined = random.sample(predefined_queries, num_predefined)
    
    for query_text in selected_predefined:
        synthetic.append({
            "query": query_text,
            "hs_code": "",
            "category": "00",
            "source": "predefined"
        })
    
    # Luego generar variaciones de queries base
    remaining = num_synthetic - len(synthetic)
    
    for _ in range(remaining):
        if not base_queries and not synthetic:
            # Si no hay queries base, usar predefinidas
            query_text = random.choice(predefined_queries)
            base_hs = ""
            base_cat = "00"
            base_source = "predefined"
        elif base_queries:
            base = random.choice(base_queries)
            query_text = base["query"]
            base_hs = base.get("hs_code", "")
            base_cat = base.get("category", "00")
            base_source = base.get("source", "unknown")
        else:
            base = random.choice(synthetic)
            query_text = base["query"]
            base_hs = base.get("hs_code", "")
            base_cat = base.get("category", "00")
            base_source = base.get("source", "unknown")
        
        # A√±adir variaci√≥n aleatoria
        variation_type = random.choice(["material", "size", "color", "condition", "origin", "brand", "none"])
        
        if variation_type == "material" and len(query_text.split()) < 8:
            new_query = f"{query_text} {random.choice(materials)}"
        elif variation_type == "size" and len(query_text.split()) < 8:
            new_query = f"{query_text} {random.choice(sizes)}"
        elif variation_type == "color" and len(query_text.split()) < 8:
            new_query = f"{query_text} {random.choice(colors)}"
        elif variation_type == "condition" and len(query_text.split()) < 8:
            new_query = f"{query_text} {random.choice(conditions)}"
        elif variation_type == "origin" and len(query_text.split()) < 8:
            new_query = f"{query_text} {random.choice(origins)}"
        elif variation_type == "brand" and len(query_text.split()) < 8:
            new_query = f"{query_text} {random.choice(brands)}"
        else:
            new_query = query_text
        
        synthetic.append({
            "query": new_query,
            "hs_code": base_hs,
            "category": base_cat,
            "source": f"synthetic:{base_source}"
        })
    
    print(f"‚úì Generadas {len(synthetic)} queries sint√©ticas")
    return synthetic


def clean_and_deduplicate(queries: List[Dict]) -> List[Dict]:
    """Limpiar y eliminar duplicados."""
    seen = set()
    cleaned = []
    
    for q in queries:
        query_text = q["query"].strip().lower()
        
        # Filtrar queries muy cortas o muy largas
        if len(query_text) < 10 or len(query_text) > 300:
            continue
        
        # Eliminar duplicados (case-insensitive)
        if query_text not in seen:
            seen.add(query_text)
            cleaned.append(q)
    
    return cleaned


def save_queries(queries: List[Dict], output_file: str):
    """Guardar queries en archivo de texto."""
    with open(output_file, 'w', encoding='utf-8') as f:
        for q in queries:
            # Formato: query|hs_code|category|source
            f.write(f"{q['query']}\n")
    
    print(f"üíæ Guardadas {len(queries)} queries en: {output_file}")


def save_queries_with_metadata(queries: List[Dict], output_file: str):
    """Guardar queries con metadata en JSON."""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(queries, f, ensure_ascii=False, indent=2)
    
    print(f"üíæ Guardado metadata en: {output_file}")


def main():
    parser = argparse.ArgumentParser(
        description="Generar queries de evaluaci√≥n desde el corpus"
    )
    parser.add_argument(
        "--os-host",
        default="http://localhost:9200",
        help="Host de OpenSearch (default: http://localhost:9200)"
    )
    parser.add_argument(
        "--os-index",
        default="tariff_fragments",
        help="√çndice de OpenSearch (default: tariff_fragments)"
    )
    parser.add_argument(
        "--os-samples",
        type=int,
        default=100,
        help="N√∫mero de documentos a muestrear de OpenSearch (default: 100)"
    )
    parser.add_argument(
        "--mysql-host",
        default="localhost",
        help="Host de MySQL (default: localhost)"
    )
    parser.add_argument(
        "--mysql-port",
        type=int,
        default=3306,
        help="Puerto de MySQL (default: 3306)"
    )
    parser.add_argument(
        "--mysql-db",
        default="corpusdb",
        help="Base de datos MySQL (default: corpusdb)"
    )
    parser.add_argument(
        "--mysql-user",
        default="appuser",
        help="Usuario MySQL (default: appuser)"
    )
    parser.add_argument(
        "--mysql-password",
        default="apppass",
        help="Password MySQL (default: apppass)"
    )
    parser.add_argument(
        "--mysql-samples",
        type=int,
        default=50,
        help="N√∫mero de registros a muestrear de MySQL (default: 50)"
    )
    parser.add_argument(
        "--use-mysql",
        action="store_true",
        help="Habilitar extracci√≥n desde MySQL"
    )
    parser.add_argument(
        "--synthetic",
        type=int,
        default=20,
        help="N√∫mero de queries sint√©ticas a generar (default: 20)"
    )
    parser.add_argument(
        "--target-total",
        type=int,
        default=100,
        help="N√∫mero total de queries objetivo (default: 100)"
    )
    parser.add_argument(
        "--output",
        default="evaluation/test_queries.txt",
        help="Archivo de salida (default: evaluation/test_queries.txt)"
    )
    parser.add_argument(
        "--metadata",
        default="evaluation/test_queries_metadata.json",
        help="Archivo de metadata (default: evaluation/test_queries_metadata.json)"
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("üîç GENERADOR DE QUERIES DE EVALUACI√ìN")
    print("=" * 60)
    
    all_queries = []
    
    # 1. Extraer de OpenSearch
    os_client = connect_opensearch(args.os_host)
    os_queries = sample_opensearch_queries(
        os_client,
        args.os_index,
        num_samples=args.os_samples
    )
    all_queries.extend(os_queries)
    
    # 2. Extraer de MySQL (opcional)
    if args.use_mysql:
        mysql_queries = sample_mysql_queries(
            args.mysql_host,
            args.mysql_port,
            args.mysql_db,
            args.mysql_user,
            args.mysql_password,
            num_samples=args.mysql_samples
        )
        all_queries.extend(mysql_queries)
    
    # 3. Limpiar y deduplicar
    all_queries = clean_and_deduplicate(all_queries)
    
    # 4. Generar sint√©ticas si no llegamos al objetivo
    if len(all_queries) < args.target_total and args.synthetic > 0:
        needed = min(args.synthetic, args.target_total - len(all_queries))
        synthetic_queries = generate_synthetic_queries(all_queries, num_synthetic=needed)
        all_queries.extend(synthetic_queries)
    
    # 5. Limitar al objetivo y mezclar
    if len(all_queries) > args.target_total:
        all_queries = random.sample(all_queries, args.target_total)
    
    random.shuffle(all_queries)
    
    # 6. Guardar
    save_queries(all_queries, args.output)
    save_queries_with_metadata(all_queries, args.metadata)
    
    print("\n" + "=" * 60)
    print("‚úÖ GENERACI√ìN COMPLETADA")
    print("=" * 60)
    print(f"üìä Total de queries: {len(all_queries)}")
    
    # Estad√≠sticas por fuente
    by_source = {}
    for q in all_queries:
        source = q.get("source", "unknown").split(":")[0]
        by_source[source] = by_source.get(source, 0) + 1
    
    print("\nüìà Distribuci√≥n por fuente:")
    for source, count in sorted(by_source.items()):
        print(f"  - {source}: {count} queries")
    
    print(f"\nüí° Siguiente paso:")
    print(f"   1. Revisar queries en: {args.output}")
    print(f"   2. Generar CSVs de evaluaci√≥n:")
    print(f"      python evaluation/tools/generate_eval_clasificador.py --queries-file {args.output} --top-n 3")
    print(f"      python evaluation/tools/generate_eval_retrieval.py --queries-file {args.output} --top-k 5")


if __name__ == "__main__":
    main()
